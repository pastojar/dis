% !Rnw root = dis.Rnw

\chapter{Theory} \label{chap2}

\rule{\textwidth}{0.4pt}
This chapter is about the theory (?and methods?) relevant for multiple following chapters. \newline
\rule[0.2cm]{\textwidth}{0.4pt}


Urban drainage systems are designed to drain waste- and stormwater from land surfaces in urban areas using combined or separate sewer networks. However, excessive amounts of stormwater can overload drainage systems and cause urban pluvial flooding and health risks due to pathogens, decrease the efficiency of wastewater treatment plants, or impact the aquatic biota of receiving waters through hydraulic stress and pollution. Therefore, the operational management of the quantity and quality of urban stormwater runoff is a serious concern in urban environmental management \citep{tsihrintzisModelingManagementUrban1997}.

Since precipitation is the essential driver of runoff processes in urban areas, rainfall observations are the key input data when designing and operating urban drainage systems during wet weather periods. Nowadays, the mitigation of the negative effects of urban drainage on society and the environment is often related to methods and concepts requiring operational rainfall products which are available in (near) real time and with a high spatial and/or temporal resolution \citep{einfaltRoadmapUseRadar2004}. Such rainfall observations are employed in real-time control strategies to optimize treatment processes at wastewater treatment plants \citep{schutzeRealTimeControl2004}, or to minimize the impacts of sewer overflows \citep{vezzaroGeneralisedDynamicOverflow2014}. Furthermore, these data are used for extreme event analyses, e.g. for the evaluation of insurance damage claims \citep{spekkersStatisticalAnalysisInsurance2013} or for operational warnings \citep{montesarchioRainfallThresholdsFlood2009}. Operational rainfall data are becoming increasingly important because of the ongoing climate change \citep{vanderpolImpactsRainfallVariability2015} as the intensity and frequency of heavy rainfall in many areas around the world are expected to increase \citep{willemsClimateChangeImpact2012}.


\section{Current rainfall monitoring practices}

In general, rainfall data of sufficient quality is lacking for most of the Earth’s land surface. To make things worse, coverage by surface precipitation gauging networks has declined in many regions around the world \citep{lorenzHydrologicalCycleThree2012}. Global precipitation data sets can be obtained from satellite missions, but the accuracy and spatiotemporal resolution of these observations are still insufficient to be used in the hydrological modelling of small, mountainous or urban catchments \citep{kiddGlobalPrecipitationMeasurement2011}.

The requirements on the temporal and spatial resolution of rainfall data are higher in urban catchments \citep[e.g.][]{schilling1991rainfall, berneTemporalSpatialResolution2004} because, hydrologically, they differ from natural ones in two fundamental aspects. Firstly, the scales of areas examined in urban and natural catchment hydrology typically differ in orders of magnitude. Secondly, urban areas are covered by a high ratio of impermeable surfaces that not only limit rainfall infiltration, but also lead to more surface runoff (e.g. causing higher peak flows) and a faster response of the runoff process.

Tipping bucket rain gauges represent the traditional way of retrieving precipitation measurements in urban areas. However, these devices often fail to provide sufficient information on the spatiotemporal variability of rainfall, frequently due to the low densities of rain gauge networks. In particular, when heavy storm events, crucial for the evaluation of urban stormwater systems, are considered, the spatial representativeness of point rainfall observations from rain gauges is limited. 

Weather radar observations have been extensively studied in recent years. Due to the inherent limitations of this technology (indirect rainfall measurement, often in relatively high altitudes above the ground and far away from the radar), radar rainfall data are commonly adjusted to rainfall measurements from rain gauges to be more advantageous for hydrological modelling \citep{harrisonHighresolutionPrecipitationEstimates2009}. These adjustments usually reduce the mean areal bias of rainfall fields, though often destroy the small-scale spatial structure of local extremes \citep{wangSingularitysensitiveGaugebasedRadar2015}. However, neglecting rainfall spatiotemporal variability at small scales can lead to substantial errors in the runoff modelling of urban catchments 
\citep{giresQuantifyingImpactSmall2012}. The smoothing of local extremes could be reduced by adjusting the radar data to dense rain gauge networks. Nevertheless, it has been concluded that traditionally available rain gauge networks and adjustment techniques do not meet the requirements of urban hydrology \citep{wangRadarRaingaugeData2013, borupDynamicGaugeAdjustment2016}. Although the usage of weather radars for urban water management applications has been extensively investigated in the past decades and substantial progress has been made towards reliable high-quality data, many challenges remain unresolved. For example, it is difficult to quantify uncertainty arising from the discrepancy between the catch area of a rain gauge (in the order of 10$^{-2}$ m$^2$) and the area of a radar pixel (in the order of 10$^4$--10$^6$ m$^2$) \citep[e.g.][]{anagnostouUncertaintyQuantificationMeanAreal1999}. Similarly, adjusting radar data in an operational mode is both a methodological and technical challenge because rain gauge data are often delivered with a delay. Finally, the availability of weather radars is mostly limited to most developed countries \citep{heistermannTechnicalNoteOpen2013}, where, even in these regions, there are observational gaps when radar observations are not available in the desired spatiotemporal resolution.

One possibility to overcome the above challenges could be so-called \enquote{opportunistic sensing} \citep{tauroMeasurementsObservationsXXI2018}. Opportunistic precipitation sensing can provide rainfall data from new types of devices which could conveniently complement traditional precipitation observation networks and, thus, improve rainfall data availability. The recent development of various accessible hardware and software solutions has made measurements with special purpose sensors widely available throughout many different fields \citep{swanSensorManiaInternet2012}. Furthermore, there are numerous online amateur weather networks that aggregate and visualize citizen-contributed weather observations \citep{gharesifardBenchmarkingCitizenObservatories2017, devosPotentialUrbanRainfall2017}. However, quality control of such crowdsourced data (and associated metadata) from amateur weather stations is extremely challenging since these devices are often uncalibrated or irregularly maintained. Furthermore, as with radar rainfall observations, this kind of data is primarily available in developed regions only.

Opportunistic sensing of precipitation can also be performed using devices not constructed primarily for rainfall observation (e.g. telecommunication infrastructure or building automation sensors), which are often connected to centralized communication infrastructure, so the data can be queried in (sub-)minute intervals. This is the case of commercial microwave links whose millimeter-wave radio signal is attenuated by rainfall droplets.


\section{Rainfall retrieval from commercial microwave links}

Commercial microwave links (CMLs) are point-to-point radio connections widely used as cellular backhaul. A substantial part of CML networks is operated at frequencies between 20 and 40 GHz where radio wave attenuation caused by raindrops is almost proportional to rainfall intensity. These CMLs can, therefore, be used as unintended rainfall sensors providing path-integrated quantitative precipitation estimates (QPEs). Moreover, CML data are accessible online in real time from network operation centers either through network monitoring systems or specifically designed server-sided applications \citep{chwalaRealtimeDataAcquisition2016}.

Although deriving precipitation estimates from the attenuation of microwaves was originally suggested several decades ago \citep{atlasPathAreaIntegratedRainfall1977}, the idea has experienced a renaissance in recent years, thanks to the extensive growth of cellular networks \citep{messer2006environmental, leijnseRainfallMeasurementUsing2007} which frequently incorporate CMLs. Recently, there has been about four million CMLs being used worldwide within cellular networks and the number has been increasing \citep{ericssonEricssonMicrowaveOutlook2016}.

The relationship between raindrop-induced attenuation $A_r$ [dB] and rainfall intensity $R$ [mm/h] is robust and well-understood. For a given rainfall intensity, $A_r$ is proportional to CML length and frequency. The relation can be expressed using the following approximation:
        \begin{equation} \label{eq:2eq1}
        % \tilde{Y}_o (x,\theta, \psi) = \tilde{y}_M (x, \theta) + B_M (\psi) + E (\psi)
        R = \alpha (A_r / L)^\beta,
        \end{equation}
where $L$ [m] is the length of a given CML, and $\alpha$ [mm/h km$^\beta$ dB$^{-\beta}$] and $\beta$ [-] are empirical parameters dependent upon CML frequency and polarization, and drop size distribution \citep{olsenARbRelationCalculation1978}. The fraction $A_r / L$ can be expressed as a single variable -- specific raindrop attenuation $\gamma$ [dB/km].

Nonetheless, $A_r$ must be separated from other components of the difference between the transmitted and received signal levels $TRSL$ [dB], for whose purposes the following relation is often used: 
        \begin{equation} \label{eq:2eq2}
        TRSL = B + A = B + A_{wa} + A_r
        \end{equation}
where $B$ [dB] represents baseline attenuation consisting of, e.g., free space loss and gaseous attenuation, $A$ [dB] stands for observed attenuation after baseline separation (henceforth referred to as “observed attenuation”), and $A_{wa}$ [dB] represents wet antenna attenuation (WAA). Imprecise quantification of the raindrop-induced attenuation $A_r$ due to CML instrumental uncertainties such as WAA estimation represents a major source of errors in CML QPEs \citep[][more details in \ref{InstErr}]{chwalaCommercialMicrowaveLink2019}.


Thanks to the extensive continental coverage of cellular networks, CMLs represent a promising rainfall sensors for hydrological modelling. The greatest potential of this technique is in areas where traditional infrastructure for rainfall measurement is, in general, insufficient \citep{gossetImprovingRainfallMeasurement2016}, e.g. in developing countries. Nevertheless, CMLs might also conveniently complement traditional monitoring networks common in developed countries, since, unlike weather radars, they observe rainfall close to the ground. Moreover, CML rainfall measurements have a path-integrated character which makes them better suited for capturing areal rainfalls over a catchment than rain gauges. 

Only a few studies have investigated the ability of QPEs derived from real-world CML networks for quantitative hydrology, either for rural \citep{brauerEffectDifferencesRainfall2016, cazzanigaCalculatingHydrologicalResponse2020, smiatekPotentialCommercialMicrowave2017}  or urban catchments \citep{dischImpactDifferentSources2019, stranskyRunoffPredictionUsing2018}. The studies from urban environments have suggested that CML QPEs could be conveniently used in combination with other rainfall data, e.g. to disaggregate cumulative rainfall measurements from point rain gauges, if available in high temporal resolutions. However, many questions regarding  applications of CML QPEs, especially correction of their systematic errors, remain open.



\section{CML QPE errors}

Most errors in CML QPEs could be linked with the following two main uncertainty types: 
\begin{itemize}
        \item Instrumental uncertainties associated with the individual microwave link measurements; 
        \item Spatial uncertainties related to the CML spatial representativeness and the way the spatial information is processed (e.g. for rainfall field reconstruction).
\end{itemize}


\subsection{Instrumental errors} \label{InstErr}

QPEs are more prone to be biased for CMLs with shorter path lengths and lower frequencies \citep{leijnseMicrowaveLinkRainfall2008}. These CMLs are less sensitive to rainfall, and raindrop-induced attenuation $A_r$ thus constitutes only a relatively small part of the observed $TRSL$ (Eq. \ref{eq:2eq2}). In other words, QPEs from these CMLs are more sensitive to errors in the process of $A_r$ estimation. Let us illustrate this problem with a brief didactic example. 

For a 1-km-long CML working at a frequency of 32 GHz, the raindrop attenuation $A_r$ caused by the rainfall of 20 mm/h is about 4 dB. However, for a CML with the same frequency and a path length of 4 km, $A_r$ equals roughly 15 dB. If $A_r$ is overestimated by 1 dB, a common value due to the instrumental uncertainties, the derived precipitation rate is overestimated by approximately 30\% for the 1-km CML, and by 10\% for the 4-km one (see Fig.~\ref{2The1}). This becomes worse if the rainfall intensity is only 3 mm/h, because the relative errors in CML QPEs rise to 175\% and 40\% for the 1-km and 4-km CMLs respectively. Furthermore, for low rainfall rates, the derived rainfall is very sensitive to the CML frequency, and thus higher errors are associated with lower frequencies.

\begin{figure}[h]
\begin{center}
\includegraphics[width=8cm]{figs/03paperI/Fig 2.jpg}
\caption{The relative error in QPEs from CMLs with vertical polarization in relation to CML path length for two rainfall intensities (3 and 20 mm/h) and three CML frequencies (26, 32, 38 GHz) as caused by an error of 1 dB in the estimate of $A_r$ due to intrumental uncertainties.} \label{2The1}
\end{center}
% \FloatBarrier
\end{figure}

The following main potential instrumental error sources were identified by \cite{leijnseErrorsUncertaintiesMicrowave2010}, with the last two being most important for the bias in the estimated rain rates \citep{chwalaCommercialMicrowaveLink2019}: 
\begin{itemize}
        \item Too coarse temporal sampling
        \item Quantization of $TRSL$ values 
        \begin{itemize}
                \item Commonly used quantization levels of the records of transmitted and received radio signal power, used to calculate $TRSL$, are 1 dB and 0.33 dB respectively
        \end{itemize}
        \item Wet antenna attenuation
        \begin{itemize}
                Details in \ref{WAAtheor}
        \end{itemize}
        \item Uncertainty of the baseline level $B$
        \begin{itemize}
                \item $B$ can be identified from dry-weather attenuation levels
        \end{itemize}
\end{itemize}




\subsubsection{Wet antenna attenuation} \label{WAAtheor}

WAA is, in contrast to $A_r$ and $B$, independent of CML path length. Previous studies \citep{leijnseMicrowaveLinkRainfall2008, overeemMeasuringUrbanRainfall2011} also suggest that it is relatively insensitive to CML frequency at bands suitable for rainfall retrieval (20--40 GHz). However, the complexity of the antenna wetting process is a major challenge to reliable WAA estimation. 

Antenna wetting is influenced not only by rainfall, but by other atmospheric conditions (e.g. wind, temperature, humidity or solar radiation) and also  antenna hardware properties \citep[e.g. antenna radome material or coating;][]{lethMeasurementCampaignAssess2018}. Thus, to date, there is no unified approach to estimate WAA and reported WAA models are often based on different assumptions and result in considerably different estimates. For example, drying times of up to several hours have been reported \citep{schleissQuantificationModelingWetAntenna2013}, whereas other studies have not considered any wetting or drying dynamics at all, relating WAA only to rainfall intensity \citep{valtrExcessAttenuationCaused2019, kharadlyEffectWetAntenna2001}. 

It has also been suggested to estimate WAA based on water quantity and distribution (droplets, rivulets, water film) on antenna radomes \citep{leijnseMicrowaveLinkRainfall2008, manciniImpactWetSBand2019}. Recently, it has been shown that WAA can be estimated using antenna reflectivity acting as a proxy variable for water film thickness \citep{moroderModelingWetAntenna2019}. However, applying this model is significantly limited by the unavailability of the required antenna reflectivity measurements.

Since having a globally valid WAA model only depending on known CML characteristics such as frequency does not seem possible, optimal WAA models should ideally be determined for each individual CML. This is especially true for models whose parameters depend on CML path length \citep[e.g.][]{kharadlyEffectWetAntenna2001}. However, optimal WAA model identification (e.g. for calibration purposes) on the level of individual CMLs is challenging, especially for real-world application with networks consisting of a high number of CMLs. As noted by \citep{ostrometzkyWetAntennaEffectFactor2018}, maintenance of dedicated equipment for the retrieval of the needed reference rainfall observations is impractical for such networks. 

Due to all the above issues, application-focused studies with city or regional-scale CML networks have often not applied any WAA correction at all \citep{chwalaPrecipitationObservationUsing2012, smiatekPotentialCommercialMicrowave2017} or have used only a simple constant offset model \citep{overeemMeasuringUrbanRainfall2011, roversiCommercialMicrowaveLinks2020, fenclAtmosphericObservationsEband2020}. Although the latter approach may be a reasonable choice when only 15-min TRSL maxima and minima are available \citep{chwalaCommercialMicrowaveLink2019}, it can introduce considerable bias in the resulting CML QPEs \citep{fenclQuantifyingWetAntenna2019}.

\cite{fenclGaugeadjustedRainfallEstimates2017} proposed adjusting the CML QPEs to measurements from traditional rain gauges if these are available in the vicinity of CMLs. Such adjusted high-resolution CML QPEs can outperform rainfall data derived only from the gauges used for adjusting \citep{fenclGaugeadjustedRainfallEstimates2017}. The adjustment, however, leads to underestimation of peak rainfalls, and it is not clear how this will affect hydrological modelling, since it has never been investigated experimentally on an extensive data set.


Calibration to reference (rainfall) data seems to be a reasonable way to achieve reliable WAA models. However, reference rainfall retrieval approaches employed in research studies which include intensive monitoring campaigns \citep[e.g.][]{schleissQuantificationModelingWetAntenna2013, lethMeasurementCampaignAssess2018} are impractical for high numbers of CMLs due to the costs associated with the dedicated equipment needed. Alternatively, already existing rain gauge networks or high-resolution weather radars might be used to calibrate the WAA models. However, as discussed above, such rainfall data sources are often not readily available to urban hydrologists. Moreover, the potential usefulness of CML QPEs increases with the decreasing availability of other rainfall (or other reference) data. Thus, it would come handy if WAA models could be calibrated using better available data and tools, such as low resolution rainfall measurements or stormwater discharge observations in combination with a rainfall-runoff model.



\subsection{Spatial errors}
(The spatial uncertainties related to interpolation are low (?) compared to individual link instrumental errors)

A lot of work was done on rainfall fields for large areas (e.g. countries). However, spatial rainfall field reconstruction from the path-integrated CML data \citep{damicoUseOperationalMicrowave2016, goldshteinRainRateEstimation2009, haeseStochasticReconstructionInterpolation2017} remains unappealing for many potential CML QPE applications, e.g. due to the low hydrological model complexity or small catchment area. For such tasks where areal rainfall estimates are satisfying and several CMLs are at hand, the influence of different CML topologies on the estimated areal rainfall \citep{fenclCommercialMicrowaveLinks2015} and simulated runoffs \citep{pastorekCommercialMicrowaveLinks2019} has been investigated. These studies have concluded that

the position of CMLs in respect to the small urban catchment affects their ability to capture rainfall-runoff dynamics, such as the onset of a runoff event, timing of the hydrograph rising limb, runoff peak, and recession limb;

CMLs with short paths, which typically correspond well to (sub-)catchment scales are often considerably biased, what compromises their usability for urban hydrology

combining QPEs from all available CMLs can very well capture the rainfall, and it is recommended when no prior information on CML data quality is available.

In addition, \cite{fenclCommercialMicrowaveLinks2015} concluded that a few very precise (i.e. least biased) CMLs will deliver the most accurate areal QPEs. However, they compared the CML QPEs only against reference rain gauge data. Nevertheless, if the QPEs are meant to be used in hydrological applications such as r-r modelling, where the spatial relations of CMLs and a catchment are of high importance, this problem should be investigated in the rainfall-runoff modelling context.

Moreover, if the bias in QPEs is relatively comparable among the CMLs, it is not clear how to identify optimal subsets of CMLs in such conditions. It remains to be investigated in what other ways such subsets could be identified efficiently. 
For example, it should be investigated whether the CML spatial relations with the catchment can be used as the only decisive criteria. If this was proved to be efficient, it could considerably improve the value added of CMLs under data scarce conditions.
Alternatively, if suitable reference data are available, the CML subsetting could be optimized by calibration to these data




\section{Rainfall Data Set Evaluation}

It is a common approach, applied as well in the studies of \cite{fenclCommercialMicrowaveLinks2015, fenclGaugeadjustedRainfallEstimates2017}, to evaluate and
benchmark rainfall data time series by a direct comparison with a referential (typically best‐casescenario)
time series. A chief problem here is the limited representativeness of the referential rainfall
data set. If, as reference, we use even high‐quality precipitation measurements, e.g. from a relatively
dense network of rain gauges, the information about precipitation included in such data can differ
significantly from the true incident rainfall over a given area. Furthermore, if we were to evaluate a
data set which better describes the ground‐truth precipitation than the referential rainfall data, the
improvement could not be captured with this approach. This could be very unfortunate especially if
we dealt with rainfall data of unknown characteristics.

River (and drainage system) discharges closely reflect transformed rainfall aggregated for a whole given catchment. Especially in urban areas, stormwater runoff can be considered as a proxy variable of the catchment areal rainfall. This can be especially useful in the case of convective precipitation when the true incident rainfall over a given area is often difficult to estimate using traditional reference rainfall measurements. Furthermore, stream discharges are typically measurable more reliably than the true incident precipitation over the given area. Therefore, when evaluating rainfall data sets for the purposes of rainfall-runoff modelling, using runoff observations and a rainfall-runoff model is a common approach. Nevertheless, it is not employed in every study with such goals. 

\cite{ochoa-rodriguezImpactSpatialTemporal2015} analyzed the impact of spatial and temporal resolution of rainfall inputs on urban hydrodynamic modelling. In this study, model outputs obtained using various rainfall data sets were evaluated using, as the reference, model outputs associated with the finest resolution rainfall estimates. Nevertheless, when using this approach, similar issues as discussed above, regarding the representativeness of the reference, can arise. Furthermore, it is unclear whether the best‐quality rainfall data lead to the best model performance in some circumstances, e.g. when the model used was calibrated using another rainfall data set.

\cite{berneTemporalSpatialResolution2004} investigated spatiotemporal rainfall‐runoff dynamics in Mediterranean urban areas in relation to , among others, rainfall measurements integration to various temporal resolutions. The relation between the precipitation and runoff was only quantified only the lag time, i.e. “the time difference between the gravity centre of the mean rainfall over the catchment on one hand and the gravity centre of the generated hydrograph on the other hand”. 

 was done also in the studies of Obled et al. (1994), Segond et al. (2007), or \citep{sikorskaValueDifferentPrecipitation2018}, although
they investigated natural catchments. Focusing specifically on urban stormwater modelling,
Kleidorfer et al. (2009) studied the impact of (artificially created) imperfections in rainfall data on urban drainage model parameters. (Goormans and Willems, 2013, Wang et al., 2015).






By employing rainfall‐runoff modelling, additional uncertainties are being introduced into the process
of rainfall data evaluation. It has been argued that ignoring the uncertainty, particularly related to
input data, compromises (not only) hydrological modelling (Beven, 2006; Kavetski et al., 2006), or
similarly, that quantification of the uncertainty associated with the models in urban stormwater
modelling is a must (Dotto et al., 2012). However, quantifying the effect of all principal uncertainty sources (or, specifically, the effect of
uncertainty related to rainfall data) on rainfall‐runoff modelling results is a complex and challenging
task. Therefore, though conceptually desirable, it is rarely practiced (Dotto et al., 2012). Researchers
have often been avoiding it by trying to maximize the reliability of modelling results, e.g. by using
data measured over a long period of time (e.g. Segond et al., 2007), or by employing “verified and
operational models” (Ochoa‐Rodriguez et al., 2015).

Whether the uncertainty analysis is employed or not, there are various methods to evaluate the
performance of a rainfall‐runoff model. The primary output of a rainfall‐runoff model is a time series
of simulated discharges at a given location. Such a time series is well suited to being evaluated
visually, creating a hydrograph. However, for numerical evaluation, it is preferable to summarize the
performance in a single metric (or a small number of metrics). Many metrics often represent only a
specific part (e.g. maximal discharge) or only a certain aspect (e.g. temporal precision, total volume
discharged) of the hydrograph. If multiple rainfall‐runoff events or even various catchments are to be
compared, it is preferable to use standardized dimensionless criteria, e.g. the relative error of
maximal discharges. Alternatively, there are metrics which take into account the whole time series
and are often applied when trying to summarize the overall model performance, such as the mean
squared error (MSE) or Nash‐Sutcliffe efficiency (NSE). These two metrics are used very commonly in hydrological modelling although it has been shown
that there are systematic problems inherent with their usage (Gupta et al., 2009).



\section{Prediction uncertainty quantification in hydrology} \label{PredUncQuant}

\cite{deleticAssessingUncertaintiesUrban2012} reviewed studies investigating uncertainty in urban hydrological modelling and identified the following key uncertainty sources:
\begin{enumerate}
        \item Model input (measured input data and parameters) uncertainties;
        \item Calibration (calibration data measuring, availability, and choices; calibration algorithms and objective functions used in the calibration process) uncertainties;
        \item Model structure (conceptualisation errors, equations and numerical methods) uncertainties. 
\end{enumerate}

Many published urban drainage modelling studies have dealt with uncertainties associated with model parameters, often producing parameter probability distributions and estimating confidence intervals around the model’s outputs \citep[e.g.][]{thorndahlEventBasedUncertainty2008, dotto2012comparison}. However, \cite{deleticAssessingUncertaintiesUrban2012} recognized that the uncertainty sources are highly interlinked, suggesting that \enqoute{assessing the impact of a single source is not going to be adequate and that simultaneous propagation of key sources of uncertainties is required}.

\cite{dotto2012comparison} observed that a common approach when trying to estimate the total uncertainty (related to parameters and all other sources) is adding a Gaussian error term to the model predictions. This approach is based on the assumption that the residuals between the measured and modelled values are normally distributed (i.e. only due to white measurement noise). However, the deviations of model outputs from observed data are usually considerably larger than random observation errors, typically due to a simplified description of the system by the deterministic model and due to input data imperfections \citep{reichert2012linking}. When ignored, such systematic deviations can lead to unrealistic (usually too narrow) uncertainty bounds of model parameters and model predictions \citep{reichert2012linking}.

Systematic deviations of model predictions from observed data, or model bias, can by addressed by increasing the complexity of the model to reduce bias or by trying to find a statistical description of the bias in model outputs. \cite{reichert2012linking} adapted a statistical technique of \cite{kennedy2001bayesian}, accounting for bias in model outputs, for purposes of environmental modelling and extended it with a framework enabling for multiobjective model calibration. \citep{sikorskaValueDifferentPrecipitation2018} used this approach to asses the value of different precipitation data for flood prediction in an alpine catchment. \cite{giudice2013improving} applied this technique to urban drainage modelling while proposing various formulations of the stochastic process representing the model bias (more in section \ref{delGiudTheor}). Their results showed that runoff simulations are much more reliable when bias is accounted for than when it is neglected. 

While approaches based on explicit model bias consideration can improve the reliability of hydrological predictions, they only provide limited information about the causes of model bias and, therefore, do not help much to distinguish imperfections in input rainfall data from model structural errors \citep{giudice2013improving}. A conceptually more satisfying approach is to make the input uncertain and to propagate it through the model. This is can be done by using so‐called rainfall multipliers \citep{kavetskiBayesianAnalysisInput2006, vrugtTreatmentInputUncertainty2008}. These random variables multiply observed rainfall rates (1 multiplier per event) before feeding it into the model. They are estimated together
with other model parameters and allow to quantify the rainfall‐related uncertainty directly in input data. \cite{sikorskaBayesianUncertaintyAssessment2012} combined a stochastic error model with rainfall multipliers to separate the effect of uncertainty in the rainfall data from other erorrs sources. However, the rainfall multiplier approach fails when the observed precipitation has a different temporal pattern from the true one or if the true nonzero rainfall is not detected \citep{delgiudiceDescribingCatchmentaveragedPrecipitation2016}. 

To overcome the above problem, \cite{delgiudiceDescribingCatchmentaveragedPrecipitation2016} introduced a method where the average precipitation over a given catchment is formulated as a stochastic process, parameters of which are inferred together with other model parameters during calibration. They showed that, even when starting with inaccurate precipitation data, this approach can accurately reconstruct the whole‐catchment precipitation and reliably quantify the related uncertainty. However, their results suggested that even a simpler approach \citep[e.g.][]{giudice2013improving} can lead to similar model parameters and prediction intervals. Therefore, if precipitation reconstructing is not of major interest, the novel approach is not appealing, given its high computational requirements.


\subsection{Performance assessment} \label{PerAsses}

When dealing with interval predictions, it is common to evaluate two aspects of the predictive performance -- its precision and accuracy. The prediction precision can be quantified by the width of the determined confidence interval, referred to also as interval sharpness \mbox{\citep[e.g.][]{breinholt2012formal}}. The prediction accuracy can be understood as the position of observed value(s) in relation to the confidence bound(s). Time series predictions such as hydrographs can also  be assessed in this manner, e.g. by calculating the prediction reliability, i.e. the share of observed data points within the predicted bounds, and the \enquote{average bandwidth} --  the interval widths averaged over the entire prediction period \citep{giudice2013improving}.

\cite{gneiting2007strictly} proposed a metric which combines the two above aspects  -- the interval score $S_\alpha$. For a single interval prediction at a confidence level $1-\alpha$ (determined by the prediction quantiles at levels $ \frac{\alpha}{2} $ and $ 1-\frac{\alpha}{2} $), the interval score 
\begin{equation}
S_\alpha(l,u,x) =  ( u - l ) + \frac{2}{\alpha} (l - x)  \mathds{1} \left\{x < l \right\} + \frac{2}{\alpha} (x - u)  \mathds{1} \left\{x > u \right\} ,
\end{equation}
where $l$ and $u$ stand for lower and upper interval bounds. This metric is supposed to allow for intuitive comprehension as \enquote{the forecaster is rewarded for narrow prediction intervals and incurs a penalty, the size of which depends on $\alpha$, if the observation misses the interval} \citep{gneiting2007strictly}.

For time series predicition, the idea of $S_\alpha$ can be extended and the mean interval scores ($M\!I\!S$) for a given period can be quantified. \cite{bourginTransferringGlobalUncertainty2015} further developed the concept and, \enquote{to ease comparison between catchments and evaluate the skill of the prediction bounds}, proposed to benchmark the prediction confidence bounds by $M\!I\!S$ for reference bounds ($M\!I\!S_{ref}$) obtained e.g. from long term climatological data. The mean interval skill score $M\!I\!S\!S$ would be computed as 
\begin{equation}
M\!I\!S\!S = 1 -  ( M\!I\!S  /  M\!I\!S_{ref} ),  
\end{equation}
high values of which indicate greater prediction skill, with positive scores indicating that evaluated predictions are more skillful than the reference.

\section{Explicit statistical consideration of model bias} \label{delGiudTheor}

Herein we describe the framework of \cite{kennedy2001bayesian} as formulated by \cite{reichert2012linking} and first used in the context of urban hydrology by \cite{giudice2013improving}. The basic principle of the method is extension of a deterministic (e.g. rainfall-runoff) model by a stochastic error model. However, a commonly used error model considering only independent and identically distributed (i.i.d.) errors is adjusted to explicitly account for the systematic model errors (bias) of the deterministic model, acknowledging the fact that simulators cannot describe the \enqoute{true} behavior of a system \citep{giudice2013improving}. Using this approach, the extended model can be formulated using the equation
\begin{equation} \label{eq:ext_model}
Y_o (x,\theta, \psi) = y_M (x, \theta) + B (\psi) + E (\psi)
\end{equation}
where variables in capitals represent random variables and those in lowercase are deterministic functions. $Y_o$ represents the observed system output, $y_M$ stands for the deterministic model output. To better fulfill the underlying statistical assumptions and thus obtain more reliable predictions, a transformation (details in \ref{transfTheor}) should be applied on both $Y_o$ and $y_M$ \citep{giudice2013improving}. Next, $B$ and $E$, respectively, stand for the bias and  measurement noise in the system output. Precipitation as the external driving force is represented by $x$, whereas $\theta$ and $\psi$ respectively represent the deterministic and error model parameters.  

The measurement noise of the system response $E$ is sampled from a multivariate normal distribution with mean 0 and a diagonal covariance matrix
\begin{equation}
\Sigma_E= \sigma_E^2 \mathds{1}
\end{equation}

\cite{giudice2013improving} investigated various formulations of the model bias $B$ and  presented a structured approach to select the optimal bias description
for a given case study. In general, it is an autoregressive term which can be dependent on the input (rainfall) or/and output (runoff) of the system. For more details, see \cite{giudice2013improving}.


By combining the deterministic hydrological and the stochastic error models, we can quantify the probability that the observed runoffs can be explained by given predicted runoffs and error model. This can be formally expressed by a likelihood function describing the joint probability density $f(Y_o|\theta, \psi, x)$ of observed system response $Y_o$ for given $\theta$, $\psi$, and $x$. It can be written as

$ f (Y_o|\theta, \psi, x) = \frac{(2\Pi)^{-\frac{n}{2}}}{\sqrt{det(\Sigma(\theta, \psi, x))}} $
\begin{equation}
. exp \Big( -\frac{1}{2}  [ \tilde{Y}_{o} - \tilde{y}_{M}(\theta, x)^{T}  \Sigma(\theta, \psi, x)^{-1} ]  [ \tilde{Y}_{o} - \tilde{y}_{M}(\theta, x)]  \prod^{n}_{i=1} \frac{dg}{dy} (Y_{o,i},\psi) \Big),
\end{equation}

where $n$ is the number of observations (i.e. the dimension of $Y_{o}$ and $y_{M}$) and $\Sigma(\theta, \psi, x)$ stands for a covariance matrix of the residuals transformed by a function $g()$. Similarly, $\tilde{y}_M=g(y_M)$.


To achieve accurate rainfall-runoff predictions and reliable quantification of their uncertainty, the extended model should be calibrated. In theory, this could be done by optimizing the likelihood function as the objective function. However, 
there is \enquote{a severe identifiability problem} between the deterministic model $y_M$ and bias $B$ \enquote{as the two components cannot be observed separately} \citep{reichert2012linking}. By implementing the Bayesian approach, i.e. combining the likelihood with prior knowledge (belief) about the extended model, we can specify that we are seeking for the smallest bias possible when calibrating the model. Although somewhat subjective choices regarding the amount of bias acceptable are required, this approach at least makes them transparent \citep{reichert2012linking}.

Performing the uncertainty analysis in the above described manner requires to follow these steps \citep{giudice2013improving}:
\begin{enumerate}
	\item  Definition of marginal distributions of the prior joint probability distribution of the both the deterministic rainfall-runoff model parameters $\theta$  and  the stochastic error model parameters $\psi$.
        \begin{itemize}
                \item \cite{giudice2013improving} suggest that completely uninformative prior distributions should not be used for neither $\theta$ nor $\psi$ parameters. Furthermore, it is \enquote{important that the prior of the bias reflects the desire to avoid model inadequacy as much as possible ... to reduce the identifiability problem between the deterministic
model and the bias}.
        \end{itemize}

	\item  Bayesian inference of the posterior parameter distribution.
	\begin{itemize}
                \item	The joint probability density, a product of the prior $f(\theta, \psi)$ and the likelihood function $f(Y_o | \theta, \psi, x)$, gets conditioned on the observed discharge data, using the Bayes' theorem
                \begin{equation}
f (\theta, \psi | Y_o, x) = \frac{ f(\theta, \psi) \, f(Y_o | \theta, \psi, x) } { \iint f(\theta' , \psi') \, f(Y_o | \theta', \psi', x) d\theta' d\psi'} \; .
                \end{equation}

Solving this problem analytically would include dealing with multidimensional integrals. This can be avoided by employing a numerical method such as Markov Chain Monte Carlo (MCMC) to approximate properties of the posterior distribution.

        \item Before the inference, a transformation $g()$  should be applied on simulation results and output data to account for the variance increasing with discharge and to reduce the heteroscedascity of residuals \citep{giudice2013improving}. Details in \ref{transfTheor}.
        \end{itemize}
        
	\item  Probabilistic predictions for the data set used for calibration
	\begin{itemize}
                \item For details on probabilistic predictions for multivariate normal distributions related to the random variables of this type, \cite{giudice2013improving} recommend to consult \cite{kendall1994vol} or \cite{kollo2006advanced}.
        \end{itemize}
	
	\item  Probabilistic predictions for unseen temporal points.
	\begin{itemize}
                \item 	It is possible to proceed analogically as above. However, \cite{giudice2013improving} suggest to take advantage of using bias formulated as an  Ornstein–Uhlenbeck process and to \enquote{draw a realization for the entire period by iteratively drawing the realization for the next time step at time   $t_ j$ from that of a previous time step at time $t_ {j-1}$ from a normal distribution}. In both cases, nevertheless, it is necessary to draw and evaluate a large sample from the  posterior parameter joint distribution.
        \end{itemize}
	
	\item Verification of the statistical assumptions
	\begin{itemize}
                \item 	In many similar cases, it is usual to confirm the statistical assumptions of the error model by residual analysis \citep{reichert2012linking}. However, Bayesian approach implemented in this method allows us to test only the observation error $E$, which is the only purely frequentist term. However, since these errors are likely to constitute only a small portion of the residuals of the deterministic simulator, the informative value of this analysis might be limited.
        \end{itemize}

	
\end{enumerate}






\subsection{Output transformation} \label{transfTheor}

Because of the  statistical assumptions of homoscedasticity and normality of calibration residuals, a transformation $g()$ should be applied on simulation and observed output data (i.e., in our case, runoff discharges).  It is a common way in hydrological modelling how to account for increasing variance with increasing discharge and thus reduce the residual heteroscedascity. Moreover, it is expected to reduce the proportion of negative flow predictions by making error distributions asymmetric \citep{giudice2013improving}.

According to \cite{giudice2013improving},  two most promising variance stabilization techniques for urban drainage
applications are the Box–Cox \citep{box1964analysis}  and the log-sinh \citep{wang2012log} transformation. The Box-Cox transformation has been used more often in hydrological studies  than the log-sinh alternative, primarily due to the date of its first introduction. The two-parameter Box–Cox transformation can be written as
\begin{equation}
 g(y)=
    \begin{cases}
      log(y+\lambda_2) , & \text{if}\ \lambda_1=0 \\
      \frac{(y+\lambda_2)^{\lambda_1}-1}{\lambda_1} , & \text{otherwise}
    \end{cases}
\end{equation}
and holds for $y > -\lambda_2$. The one-parameter version would need only  $\lambda_1$  while keeping $\lambda_2 = 0$. \cite{giudice2013improving} used the one-parameter version of the transformation with the parameter value $\lambda_1=0.35$, which had already been proven to perform satisfactorily in the past \citep[e.g.][]{honti2013integrated, wang2012log}.

The log-sinh transformation was introduced for hydrological purposes only recently by \cite{wang2012log}. \cite{giudice2013improving}  proposed its modification which would result in a \enquote{reparameterised form with parameters that have a more intuitive meaning}. The formula would be
\begin{equation}
g(y)= \beta \, log \Big(sinh \big( \frac{\alpha+y}{\beta} \big) \Big),
\end{equation}
where $\alpha$ and $\beta$ represent lower and upper reference outputs. This means that \\ \enquote{$\alpha$ controls how the relative error increases for low flows} and \enquote{for outputs larger than $\beta$, the absolute error gradually stops increasing} \citep{giudice2013improving}.






