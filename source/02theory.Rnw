% !Rnw root = dis.Rnw

\chapter{Theory} \label{chap2}

\rule{\textwidth}{0.4pt}
This chapter is about the theory (?and methods?) relevant for multiple following chapters. \newline
\rule[0.2cm]{\textwidth}{0.4pt}


Urban drainage systems are designed to drain waste- and stormwater from land surfaces in urban areas using combined or separate sewer networks. However, excessive amounts of stormwater can overload drainage systems and cause urban pluvial flooding and health risks due to pathogens, decrease the efficiency of wastewater treatment plants, or impact the aquatic biota of receiving waters through hydraulic stress and pollution. Therefore, the operational management of the quantity and quality of urban stormwater runoff is a serious concern in urban environmental management (Tsihrintzis and Hamid, 1997).

Since precipitation is the essential driver of runoff processes in urban areas, rainfall observations are the key input data when designing and operating urban drainage systems during wet weather periods. Nowadays, the mitigation of the negative effects of urban drainage on society and the environment is often related to methods and concepts requiring operational rainfall products which are available in (near) real time and with a high spatial and/or temporal resolution (Einfalt et al., 2004). Such rainfall observations are employed in real-time control strategies to optimize treatment processes at wastewater treatment plants (Schütze et al., 2004), or to minimize the impacts of sewer overflows (Vezzaro and Grum, 2014). Furthermore, these data are used for extreme event analyses, e.g. for the evaluation of insurance damage claims (Spekkers et al., 2013) or for operational warnings (Montesarchio et al., 2009). Operational rainfall data are becoming increasingly important because of the ongoing climate change (van der Pol et al., 2015) as the intensity and frequency of heavy rainfall in many areas around the world are expected to increase (Willems et al., 2012).


\section{Current rainfall monitoring practices}

In general, rainfall data of sufficient quality is lacking for most of the Earth’s land surface. To make things worse, coverage by surface precipitation gauging networks is declining in many regions around the world (Lorenz and Kunstmann, 2012). Global precipitation data sets can be obtained from satellite missions, but the accuracy and spatiotemporal resolution of these observations are still insufficient to be used in the hydrological modelling of small, mountainous or urban catchments (Kidd and Huffman, 2011).

The requirements on the temporal and spatial resolution of rainfall data are higher in urban catchments (e.g. Schilling, 1991; Berne et al., 2004) because, hydrologically, they differ from natural ones in two fundamental aspects. Firstly, the scales of areas examined in urban and natural catchment hydrology typically differ in orders of magnitude. Secondly, urban areas are covered by a high ratio of impermeable surfaces that not only limit rainfall infiltration, but also lead to more surface runoff (e.g. causing higher peak flows) and a faster response of the runoff process.

Tipping bucket rain gauges represent the traditional way of retrieving precipitation measurements in urban areas. However, these devices often fail to provide sufficient information on the spatiotemporal variability of rainfall, frequently due to the low densities of rain gauge networks. In particular, when heavy storm events, crucial for the evaluation of urban stormwater systems, are considered, the spatial representativeness of point rainfall observations from rain gauges is limited. 

Weather radar observations have been extensively studied in recent years. Due to the inherent limitations of this technology (indirect rainfall measurement, often in relatively high altitudes above the ground and far away from the radar), radar rainfall data are commonly adjusted to rainfall measurements from rain gauges to be more advantageous for hydrological modelling (Harrison et al., 2009). These adjustments usually reduce the mean areal bias of rainfall fields, though often destroy the small-scale spatial structure of local extremes (Wang et al., 2015). However, neglecting rainfall spatiotemporal variability at small scales can lead to substantial errors in the runoff modelling of urban catchments (e.g. Gires et al., 2012). The smoothing of local extremes could be reduced by adjusting the radar data to dense rain gauge networks. Nevertheless, it has been concluded that traditionally available rain gauge networks and adjustment techniques do not meet the requirements of urban hydrology (Wang et al., 2013; Borup et al., 2016). Although the usage of weather radars for urban water management applications has been extensively investigated in the past decades and substantial progress has been made towards reliable high-quality data, many challenges remain unresolved. For example, it is difficult to quantify uncertainty arising from the discrepancy between the catch area of a rain gauge (in the order of 10$^{-2}$ m$^2$) and the area of a radar pixel (in the order of 10$^4$--10$^6$ m$^2$) (e.g. Anagnostou et al., 1999). Similarly, adjusting radar data in an operational mode is both a methodological and technical challenge because rain gauge data are often delivered with a delay. Finally, the availability of weather radars is mostly limited to developed countries (Heistermann et al., 2013), where, even in these regions, there are observational gaps when radar observations are not available in the desired spatiotemporal resolution.


\section{Opportunistic precipitation data collection}

One possibility to overcome the above challenges could be so-called \enquote{opportunistic sensing} (Tauro et al., 2018). Opportunistic precipitation sensing can provide rainfall data from new types of devices which could conveniently complement traditional precipitation observation networks and, thus, improve rainfall data availability. The recent development of various accessible hardware and software solutions has made measurements with special purpose sensors widely available throughout many different fields (Swan, 2012). Furthermore, there are numerous online amateur weather networks that aggregate and visualize citizen-contributed weather observations (Gharesifard et al., 2017, de Vos et al., 2017). However, quality control of such crowdsourced data (and associated metadata) from amateur weather stations is extremely challenging since these devices are often uncalibrated or irregularly maintained. Furthermore, as with radar rainfall observations, this kind of data is primarily available in developed regions only.

Opportunistic sensing of precipitation can also be performed using devices not constructed primarily for rainfall observation (e.g. telecommunication infrastructure or building automation sensors), which are often connected to centralized communication infrastructure, so the data can be queried in (sub-)minute intervals. This is the case of commercial microwave links whose millimeter-wave radio signal is attenuated by rainfall droplets.


\section{Rainfall retrieval from commercial microwave links}

Commercial microwave links (CMLs) are point-to-point radio connections widely used as cellular backhaul. A substantial part of CML networks is operated at frequencies between 20 and 40 GHz where radio wave attenuation caused by raindrops is almost proportional to rainfall intensity. These CMLs can, therefore, be used as unintended rainfall sensors providing path-integrated quantitative precipitation estimates (QPEs). Moreover, CML data are accessible online in real time from network operation centers either through network monitoring systems or specifically designed server-sided applications (Chwala et al., 2016).

Although deriving precipitation estimates from the attenuation of microwaves was originally suggested several decades ago (Atlas and Ulbrich, 1977), the idea has experienced a renaissance in recent years, thanks to the extensive growth of cellular networks (Messer et al., 2006, Leijnse et al., 2007) which frequently incorporate CMLs. Presently, there are about four million CMLs being used worldwide within cellular networks and the number is increasing (Ericsson, 2016).

The relationship between raindrop-induced attenuation $A_r$ [dB] and rainfall intensity $R$ [mm/h] is robust and well-understood. For a given rainfall intensity, $A_r$ is proportional to CML length and frequency. The relation can be expressed using the following approximation: 

\begin{equation} \label{2eq1}
% \tilde{Y}_o (x,\Theta, \psi) = \tilde{y}_M (x, \Theta) + B_M (\psi) + E (\psi)
R = \alpha (A_r / L)^\beta,
\end{equation}


where $L$ [m] is the length of a given CML, and $\alpha$ [mm/h km$^\beta$ dB$^{-\beta}$] and $\beta$ [-] are empirical parameters dependent upon CML frequency and polarization, and drop size distribution (Olsen et al., 1978).

Nonetheless, $A_r$ must be separated from other components of total (observed) attenuation $A$ [dB], for whose purposes the following relation is often used: 

\begin{equation} \label{2eq2}
A_r = (A - A_w - B)
\end{equation}

where $A_w$ [dB] stands for attenuation caused by antenna wetting, and $B$ [dB] for rainfall-independent \enquote{baseline} attenuation. The latter can be identified from dry-weather attenuation levels. However, quantifying $A_w$ is still challenging, although it is (in contrast to $A_r$ and $B$) independent of CML path length and previous studies (Leijnse et al., 2008; Overeem et al., 2011) suggest that it is relatively insensitive to CML frequency at bands suitable for rainfall retrieval (20--40 GHz). Nevertheless, antenna wetting is a complex process influenced not only by rainfall, but by other atmospheric conditions, such as wind, temperature, humidity or solar radiation, and also antenna radome material or coating (Leth et al., 2018). This complexity (and site-specificity) is probably why $A_w$ models suggested in the literature (Leijnse et al., 2008; Overeem et al., 2011; Schleiss et al., 2013) are often based on different assumptions and result in considerably different $A_w$ estimates. Therefore, the resulting rainfall estimates are frequently highly biased, especially for CMLs with shorter paths and lower frequencies which are less sensitive to raindrop-induced attenuation $A_r$ (Leijnse et al., 2008). 



\section{CML QPE errors}

Most errors in CML QPEs could be linked with two main uncertainty types: 1) instrumental errors associated with the individual microwave link measurements and 2) spatial uncertainties related to the CML spatial representativeness and the way the spatial information is processed (e.g. for rainfall field reconstruction).


\subsection{Instrumental errors} \label{InstErr}

The following main potential instrumental error sources were identified by Leijnse et al. (2010): 

too coarse temporal sampling, 

quantization of TRSL values, 

uncertainty of the baseline level, 

and wet antenna attenuation, 

with the latter two being most important for the bias in the estimated rain rates (Chwala and Kunstmann, 2019). 

Inaccurate correction for WAA is a major cause of the bias in CML QPEs. This problem is illustrated with a brief didactical example: For a 1-km-long CML working at a frequency of 32 GHz, the attenuation caused by rainfall ($A_r$) of 20 mm/h is about 4 dB. However, for a CML with the same frequency and a path length of 4 km, $A_r$ equals roughly 15 dB. If $A_r$ is overestimated by 1 dB, a common value due to the uncertainties associated with $A_w$, the derived precipitation rate is overestimated by approximately 30\% for the 1-km CML, and by 10\% for the 4-km one (see Fig. \ref{2fig2}). This becomes worse if the rainfall intensity is only 3 mm/h, because the relative errors in CML QPEs rise to 175\% and 40\% for the 1-km and 4-km CMLs respectively. Furthermore, for low precipitation rates, the derived rainfall is very sensitive to the CML frequency, and thus higher errors are associated with lower frequencies.

Moreover, commonly used quantization levels of the records of transmitted and received radio signal power, used to calculate total observed attenuation $A$, are 1 dB and 0.33 dB respectively. Therefore, these quantization levels can have a similar effect on the errors in CML QPEs as an imprecise estimation of the attenuation due to antenna wetting.

\begin{figure}[h]
\begin{center}
\includegraphics[width=8cm]{02paperI/Fig 2.jpg}
\caption{The relative error in QPEs from CMLs, with vertical polarization in relation to CML path length, for two rainfall intensities (3 and 20 mm/h) and three CML frequencies (26, 32, 38 GHz), as caused by an error of 1 dB in the estimate of wet antenna attenuation.} \label{2fig2}
\end{center}
% \FloatBarrier
\end{figure}

Therefore, many studies have recently addressed innovations in WAA estimation (Fencl et al., 2017, Moroder et al., 2019; Schleiss et al., 2013; Valtr et al., 2019).

Fencl et al. (2017) proposed adjusting the CML QPEs to measurements from traditional rain gauges if these are available in the vicinity of CMLs. According to Fencl et al. (2017), such adjusted high-resolution CML QPEs can outperform rainfall data derived only from the gauges used for adjusting. The adjustment, however, leads to underestimation of peak rainfalls, and it is not clear how this will affect hydrological modelling, since it has never been investigated experimentally on an extensive data set.

The bias can be notably reduced if an accurate WAA estimation model is used. However, having a globally valid WAA model only depending on known CML characteristics such as frequency does not seem possible due to the WAA dependency on specific CML antenna parameters (material of the antenna cover, type and aging of hydrophobic coating on the antenna cover) (Chwala and Kunstmann, 2019; van Leth et al., 2018). Reliable WAA models can be achieved by calibration to reference (rainfall) data



\subsection{Spatial errors}
(The spatial uncertainties related to interpolation are low (?) compared to individual link instrumental errors)

A lot of work was done on rainfall fields for large areas (e.g. countries). However, spatial rainfall field reconstruction from the path-integrated CML data (D’Amico et al., 2016; Goldshtein et al., 2009; Haese et al., 2017) remains unappealing for many potential CML QPE applications, e.g. due to the low hydrological model complexity or small catchment area. For such tasks where areal rainfall estimates are satisfying and several CMLs are at hand, the influence of different CML topologies on the estimated areal rainfall Fencl et al. (2015) and simulated runoffs (Pastorek et al., 2019b) has been investigated. These studies have concluded that

the position of CMLs in respect to the small urban catchment affects their ability to capture rainfall-runoff dynamics, such as the onset of a runoff event, timing of the hydrograph rising limb, runoff peak, and recession limb;

CMLs with short paths, which typically correspond well to (sub-)catchment scales are often considerably biased, what compromises their usability for urban hydrology

combining QPEs from all available CMLs can very well capture the rainfall, and it is recommended when no prior information on CML data quality is available.

In addition, Fencl et al. (2015) concluded that a few very precise (i.e. least biased) CMLs will deliver the most accurate areal QPEs. However, they compared the CML QPEs only against reference rain gauge data. Nevertheless, if the QPEs are meant to be used in hydrological applications such as r-r modelling, where the spatial relations of CMLs and a catchment are of high importance, this problem should be investigated in the rainfall-runoff modelling context.

Moreover, if the bias in QPEs is relatively comparable among the CMLs, it is not clear how to identify optimal subsets of CMLs in such conditions. It remains to be investigated in what other ways such subsets could be identified efficiently. 
For example, it should be investigated whether the CML spatial relations with the catchment can be used as the only decisive criteria. If this was proved to be efficient, it could considerably improve the value added of CMLs under data scarce conditions.
Alternatively, if suitable reference data are available, the CML subsetting could be optimized by calibration to these data





\section{Hydrological applications of CML QPEs}

Thanks to the extensive continental coverage of cellular networks, CMLs represent a promising rainfall sensors for hydrological modelling. The greatest potential of this technique is in areas where traditional infrastructure for rainfall measurement is, in general, insufficient (Gosset et al., 2016), e.g. in developing countries. Nevertheless, CMLs might also conveniently complement traditional monitoring networks common in developed countries, since, unlike weather radars, they observe rainfall close to the ground. Moreover, CML rainfall measurements have a path-integrated character which makes them better suited for capturing areal rainfalls over a catchment than rain gauges. 

To date, only a few studies with limited data sets studied the ability of CML QPEs for quantitative hydrology. Smiatek et al. (2017) investigated the potential of QPEs from CMLs for streamflow prediction in an orographically complex mountainous region and found out that the CML QPEs improved hydrograph reproduction for strong local rainfall events. Stránský et al. (2018) demonstrated for a case study in Tábor, Czech Rep., that, at city scale, using CMLs together with rain gauges can improve urban drainage modelling in terms of peak flows, especially their timing.


\section{Rainfall‐Runoff Modelling Evaluation}

Whether the uncertainty analysis is employed or not, there are various methods to evaluate the
performance of a rainfall‐runoff model. The primary output of a rainfall‐runoff model is a time series
of simulated discharges at a given location. Such a time series is well suited to being evaluated
visually, creating a hydrograph. However, for numerical evaluation, it is preferable to summarize the
performance in a single metric (or a small number of metrics). Many metrics often represent only a
specific part (e.g. maximal discharge) or only a certain aspect (e.g. temporal precision, total volume
discharged) of the hydrograph. If multiple rainfall‐runoff events or even various catchments are to be
compared, it is preferable to use standardized dimensionless criteria, e.g. the relative error of
maximal discharges. Alternatively, there are metrics which take into account the whole time series
and are often applied when trying to summarize the overall model performance, such as the mean
squared error (MSE) or Nash‐Sutcliffe efficiency (NSE).

Criteria used for model performance evaluation are employed as objective functions when
performing an automated model calibration. It has been noted that all objective functions sacrifice
the fit of a certain portion of the dataset in order to achieve a good performance in another portion
(Wagener et al., 2004). In other words, the choice of objective function can impact the model
parameter values, and, therefore, it is essential that objective functions are matched to the purpose
and requirements of the modelling application (Deletic et al., 2012). However, especially the MSE
and NSE criteria are used very commonly in hydrological modelling, even though it has been shown
that there are systematic problems inherent with such optimizations (Gupta et al., 2009).

Imperfections of the common automated calibration routines led to applying multicriteria
optimization techniques, which should more closely reflect the practice of manual model calibration,
when modelers carefully make trade‐offs among different characteristic sections of a hydrograph
(Reichert and Schuwirth, 2012). Many such techniques lead to the determination of a Pareto set of
parameters. The main property of these sets is that for each point in the set the degree of fulfilment
of none of the objectives can be improved without reducing the degree of fulfilment of another
objective when changing parameter values. However, a major issue of this approach is that it is
unclear how we should interpret the ranges of simulation results that correspond to a given Pareto
set of parameters, since no probabilistic description of inference results is provided (Reichert and
Schuwirth, 2012).

When performing uncertainty analysis and thus producing parameter probability distributions and
estimating confidence intervals around the model’s outputs, it is common to evaluate the model
predictive performance, no matter what metric used, from two aspects: i) the width of the
determined confidence interval, referred to also as interval sharpness (e.g. Breinholt et al., 2012),
and ii) the reliability of the predictions represented by the share the observed data included within
the confidence interval. The sharpness and reliability can be combined into a single performance

measure (“the interval skill score”; Gneiting and Raftery, 2007) that rewards narrow and reliable
confidence bounds. In the case of model outputs in the form of discharge time series, the prediction
intervals can be plotted as a hydrograph, creating prediction bands (also bounds). Similarly as in the
case of simple deterministic predictions, visual evaluation of such hydrographs could be quite
intuitive, however, numerical evaluation is more straightforward when using summarizing
performance metrics.



\section{Prediction uncertainty quantification} \label{PredUncQuant}

Deletic et al. (2012) reviewed studies investigating uncertainty in urban hydrological modelling and identified the following key uncertainty sources:
\begin{enumerate}
        \item Model input (measured input data and parameters) uncertainties;
        \item Calibration (calibration data measuring, availability, and choices; calibration algorithms and objective functions used in the calibration process) uncertainties;
        \item Model structure (conceptualisation errors, equations and numerical methods) uncertainties. 
\end{enumerate}

Many published urban drainage modelling studies have dealt with uncertainties associated with model parameters, often producing parameter probability distributions and estimating confidence intervals around the model’s outputs (e.g. Thorndal et al., 2008; Dotto et al., 2012). However, Deletic et al. (2012) recognized that the uncertainty sources are highly interlinked, “suggesting that assessing the impact of a single source is not going to be adequate and that simultaneous propagation of key sources of uncertainties is required.”

Dotto et al. (2011) observed that a common approach when trying to estimate the total uncertainty
(related to parameters and all other sources) is adding a Gaussian error term to the model
predictions. This approach is based on the assumption that the residuals between the measured and
modelled values are normally distributed (only due to white measurement noise). However, the
deviations of model outputs from observed data are usually considerably larger than random
observation errors, typically due to a simplified description of the system by the deterministic model
and due to input data imperfections (Reichert and Schuwirth, 2012). When ignored, such systematic
deviations can lead to unrealistic (usually too narrow) uncertainty bounds of model parameters and
model predictions (Reichert and Schuwirth, 2012).

Systematic deviations of model results from observed data, or model bias, can by addressed by
increasing the complexity of the model to reduce bias or by trying to find a statistical description of
bias in model outputs. Reichert and Schuwirth (2012) adapted a statistical technique of Kennedy and
O’Hagan (2001), accounting for bias in model outputs, for purposes of environmental modelling and
extended it with a framework enabling for multiobjective model calibration. Del Giudice et al. (2013)
later applied this technique to urban drainage modelling while proposing various formulations of the
stochastic process representing the model bias {\ref{delGiudTheor}}.

While approaches based on explicit model bias consideration can improve the reliability of
hydrological predictions, they only provide limited information about the causes of model bias and,
therefore, do not help much to distinguish imperfections in input rainfall data from model structural
errors (Del Giudice et al., 2016). A conceptually more satisfying approach is to make the input
uncertain and to propagate it through the model. This is can be done by using so‐called rainfall
multipliers (Kavetski et al., 2006; Vrugt et al., 2008). These random variables multiply observed
rainfall rates (1 multiplier per event) before feeding it into the model. They are estimated together
with other model parameters and allow to quantify the rainfall‐related uncertainty directly in input
data.

However, the rainfall multiplier approach fails when the observed precipitation has a different
temporal pattern from the true one or if the true nonzero input is not detected (Del Giudice et al.,
2016). In order to overcome this problem, Del Giudice et al. (2016) introduced a method where the
average precipitation over a given catchment is formulated as a stochastic process, parameters of
which are inferred together with other model parameters during calibration. Del Giudice et al. (2016)
showed that, even when starting with inaccurate precipitation data, this approach can accurately
reconstruct the whole‐catchment precipitation and reliably quantify the related uncertainty.
However, even a simpler approach (e.g. Del Giudice et al., 2013) can lead to similar model
parameters and prediction intervals. Therefore, if precipitation reconstructing is not of major
interest, the novel approach is not recommendable, given its high computational requirements.


\subsection{Explicit statistical consideration of the bias} \label{delGiudTheor}

 a method first used in a similar context by \cite{giudice2013improving}. The basic principle of the chosen method is the extension of the deterministic rainfall-runoff model by a stochastic error model. However, a commonly used error model considering only independent and identically distributed (i.i.d.) errors is adjusted to explicitly account for the systematic model errors (bias) of the rainfall-runoff model. The extended model can be thus formulated using the equation
\begin{equation}
\tilde{Y} (x,\Theta, \psi) = \tilde{y} (x, \Theta) + B (\psi) + E (\psi)
\end{equation}
where $\tilde{Y}$ is the transformed (\ref{transfTheor}) observed system output, $\tilde{y}$ represents the transformed deterministic model predictions, $B$ stands for the  model bias (\ref{biasTheor}) and $E$ for the i.i.d. errors. Precipitation as the external driving force is represented by $x$, whereas $\Theta$ and $\psi$ respectively represent the deterministic and error model parameters. Representing the measurement noise of the system response, $E$ is sampled from a multivariate normal distribution with mean 0 and a diagonal covariance matrix
\begin{equation}
\Sigma_E= \sigma_E^2 \mathds{1}
\end{equation}

By combining the deterministic hydrological and the stochastic error models, we can quantify the probability that the observed runoffs can be explained by the given predicted runoffs and error model. This can be formally expressed by a likelihood function (\ref{LikeliTheor}) describing the joint probability density of the observed system outcomes, i.e. the extended model. To achieve accurate rainfall-runoff predictions and reliable quantification of their uncertainty, the extended model should be calibrated. In theory, this could be done by optimizing the likelihood function as the objective function. However, by implementing the Bayesian approach, i.e. combining the likelihood with prior knowledge (belief) about the extended model, we can ...

Calibration of our deterministic model (parameters $\Theta$) expanded by the error model (parameters $\psi$) using the statistical bias description method and subsequent analysis of prediction uncertainties require to follow these steps \citep{giudice2013improving}:
\begin{itemize}
	\item  definition of the prior distributions of the parameters
	\item  obtaining the posterior distributions with Bayesian inference
	\item  probabilistic predictions for  data used for calibration
	\item  probabilistic predictions for unseen data (extrapolation)
	\item  assessment of the predictions quality
	\item verification of the statistical assumptions
\end{itemize}


\subsubsection{Bias formulation} \label{biasTheor}

...

...

The bias $B$ is formulated as an autoregressive stationary random process with a long-term equilibrium value of zero and a constant variance. \enquote{It is a mean-reverting OU process \citep{uhlenbeck1930theory}, the discretisation of which would be a first-order autoregressive process with Gaussian independent and identically distributed noise} \citep{giudice2013improving}. It can be expressed using the following differential equation:
\begin{equation} 
dB (t)= - \frac{B (t)}{\tau}dt + \sqrt{\frac{2}{\tau}} \sigma_{B_{ct}}  dW(t),
\end{equation}
where $\tau$ represents the correlation time, $\sigma_{B_{ct}}$ the asymptotic standard deviation of the random fluctuations around the equilibrium and $dW(t)$ a Wiener process (standard Brownian motion). Although there has been some research on using more sophisticated, e.g. model input- or output-dependent, bias formulation \citep{honti2013integrated}, we have decided to follow the recommendations of \cite{giudice2013improving} and to employ the simpler constant bias formulation.



\subsubsection{Output transformation} \label{transfTheor}

Because of the  statistical assumptions of homoscedasticity and normality of calibration residuals, we apply a transformation $g()$ on simulation results and output data.  According to  \cite{giudice2013improving}, it is a common way in hydrological modelling how to account for increasing variance with increasing discharge and to reduce the heteroscedascity.

According to \cite{giudice2013improving},  two most promising variance stabilization techniques for urban drainage
applications are the Box–Cox \citep{box1964analysis}  and the log-sinh \citep{wang2012log} transformation. Another motivation for applying such transformation is to reduce the proportion of negative flow predictions by making error distributions asymmetric.

The Box-Cox transformation has been used more often in hydrological studies \\ \citep{giudice2013improving} than the log-sinh alternative, primarily due to the date of its first introduction by \cite{box1964analysis}. The two-parameter Box–Cox transformation can be written as
\begin{equation}
 g(y)=
    \begin{cases}
      log(y+\lambda_2) , & \text{if}\ \lambda_1=0 \\
      \frac{(y+\lambda_2)^{\lambda_1}-1}{\lambda_1} , & \text{otherwise}
    \end{cases}
\end{equation}
and holds for $y > -\lambda_2$. The one-parameter version would need only  $\lambda_1$  while keeping $\lambda_2 = 0$.

\cite{giudice2013improving} decided to use the one-parameter version of the transformation with the parameter value $\lambda_1=0.35$, which had already been proven to perform satisfactorily in the past \citep[e.g.][]{honti2013integrated, wang2012log}.


The log-sinh transformation was introduced for hydrological purposes only recently by \cite{wang2012log}. \cite{giudice2013improving}  decided to modify its formulation, to use a \enquote{reparameterised form with parameters that have a more intuitive meaning}. The formula would be
\begin{equation}
g(y)= \beta \, log \Big(sinh \big( \frac{\alpha+y}{\beta} \big) \Big),
\end{equation}
where $\alpha$ and $\beta$ represent lower and upper reference outputs. This means that \\ \enquote{$\alpha$ controls how the relative error increases for low flows} and \enquote{for outputs larger than $\beta$, the absolute error gradually stops increasing} \citep{giudice2013improving}.




\subsubsection{Likelihood function} \label{LikeliTheor}

The likelihood function combines the deterministic hydrological model with a stochastic error term and describes the joint probability density $ f (y_{o}|\Theta, \psi, x) $ of observed system outcomes ($y_{0}$) for given (simulator and error model) parameters  and external driving forces (precipitation, $x$). The equation can be written as

$ f (y_{o}|\Theta, \psi, x) = $
\begin{equation}
 \frac{(2\Pi)^{-\frac{n}{2}}}{\sqrt{det(\Sigma(\Theta, \psi, x))}}  . exp \Big( -\frac{1}{2}  [ \tilde{y}_{o} - \tilde{y}_{M}(\Theta, x)^{T}  \Sigma(\Theta, \psi, x)^{-1} ]  [ \tilde{y}_{o} - \tilde{y}_{M}(\Theta, x)]  \prod^{n}_{i=1} \frac{dg}{dy} (y_{o,i},\psi) \Big),
\end{equation}

where $\Sigma(\Theta, \psi, x)$ stands for a covariance matrix of the residuals transformed by a function $g()$, i.e. $\tilde{y}=g(y)$. Observed values are represented by $y_{o}$, deterministic model predictions by $y_{M}$ and $n$ is the number of observations (the dimension of $y_{o}$ and $y_{M}$).



\subsubsection{Prior definition} \label{priorTheor}
The first step is to define marginal distributions of the prior joint probability distribution of the parameters of  both the deterministic hydrological model ($\Theta$) and the error model ($\psi$, i.e. $\tau$,  $\sigma_{B_{ct}}$ and  $\sigma_E$). 

 For example, we recognize that $\sigma_{B_{ct}}$ is unlikely to be higher than the variability of observed discharge, $\tau$ should represent the characteristic correlation length of the residuals and  $\sigma_E$ mirrors the measurement noise of the system output. Furthermore, according to \cite{giudice2013improving}, it is \enquote{important that the prior of the bias reflects the desire to avoid model inadequacy as much as possible}. 




\subsubsection{Calibration using Bayesian inference} \label{calibTheor}
Another step is to obtain the posterior joint distribution of the parameters $ f (\Theta, \psi | y_o, x) $. Using the notation of \cite{giudice2013improving}, we can write the Bayes' theorem as
\begin{equation}
 f (\Theta, \psi | y_o, x) = \frac{ f(\Theta, \psi) \, f(y_o | \Theta, \psi, x) } { \iint f(\Theta' , \psi') \, f(y_o | \Theta', \psi', x) d\Theta' d\psi'} \; ,
\end{equation}
where $f(\Theta, \psi)$ is the prior distribution  and $ f(y_o | \Theta, \psi, x)$ the likelihood function.

Using this relation, the joint probability density, a product of the prior and the likelihood function, gets conditioned on the data. It is an iterative process, meaning that the posterior distribution of the step $i-1$ serves as prior for the step $i$.

To solve this problem analytically would include dealing with multidimensional integrals. This can be avoided by employing a numerical method such as Markov Chain Monte Carlo (MCMC) to approximate properties of the posterior distribution. 



\subsubsection{Probabilistic predictions}
The third step is to compute predictive distributions for the data points (observations) that have been used for the calibration process. 

It should be noted that the word \enquote{predictions} in this context represents  generation of model outputs in general, consistently with e.g. \cite{reichert2012linking} or \cite{giudice2013improving}, in contrast to simulation only for time points or locations where measurements are not available. In other words, using the terminology of \cite{breinholt2012formal}, our model is tailored as an off-line simulation model suitable rather for long-term investigations than for forecasting in  real time.

For details on how to calculate probabilistic predictions for multivariate normal distributions related to the random variables of our type,  \cite{giudice2013improving} recommend to consult \cite{kendall1994vol} or \cite{kollo2006advanced}.

Subsequently, one should calculate predictive distributions for unseen temporal points (observations not used for the calibration process), also called \enquote{extrapolation layout} by \cite{giudice2013improving}. It is possible to proceed analogically as outlined above. However, \cite{giudice2013improving} suggest to take advantage of using bias formulated as an  OU process and to \enquote{draw a realization for the entire period by iteratively drawing the realization for the next time step at time   $t_ j$ from that of a previous time step at time $t_ {j-1}$ from a normal distribution}.

In both cases, nevertheless, it is necessary to draw a large sample from the  posterior parameter joint distribution and to propagate it through the deterministic model. Separating different uncertainty components is enabled by expanding the transformed simulator output $\tilde{y}_M$ with the model bias $B_M$ and independent error $E$ terms (see the equation (3.2)). Subsequently, the results are transformed back to the original space using the inverse transformation $g^{-1}()$.

To be able to visualize and distinguish uncertainty of the deterministic simulator predictions $y_M$, the best knowledge about the system response $g^{-1}(\tilde{y}_M+ B_M)$ and the modelled observed system response (including flow measurement errors) $Y_o= g^{-1}(\tilde{y}_M+ B_M + E)$, it is profitable to compute sample quantiles (e.g. $0.05$, $0.5$ and $0.095$) of the respective calculated predictions in every time step.



\subsection{Performance assessment}
To conclude uncertainty analysis, quality of the predictions (propagations of the sample from the posterior joint parameter distribution) should be evaluated and underlying statistical assumptions verified \citep{giudice2013improving}. 

When dealing with interval predictions at a certain confidence level $1-\alpha$ (determined by the predictive quantiles at level $ \frac{\alpha}{2} $ and $ 1-\frac{\alpha}{2} $) as in our case, it is common to evaluate the model predictive performance by two metrics: width of the determined confidence interval, referred to also as interval sharpness \mbox{\citep[e.g.][]{breinholt2012formal}} and reliability of the predictions represented by the share the observed data included within the confidence bounds.

\cite{giudice2013improving} assessed the model predictive capability also in this manner, evaluating the uncertainty bands  by calculating the predictions reliability and the \enquote{average bandwidth} --  the interval widths averaged over the entire prediction period.

 a metric which combines them -- the interval score $S_\alpha$ as formulated by \cite{gneiting2007strictly}. For a single interval prediction, the interval score 
\begin{equation}
S_\alpha(l,u,x) =  ( u - l ) + \frac{2}{\alpha} (l - x)  \mathds{1} \left\{x < l \right\} + \frac{2}{\alpha} (x - u)  \mathds{1} \left\{x > u \right\} ,
\end{equation}
where $l$ and $u$ stand for lower and upper interval bounds (quantiles at levels $ \frac{\alpha}{2} $ and $ 1-\frac{\alpha}{2} $ ). The evaluated variable $x$ stands in our case for the modelled system response including measurement errors $Y_o$. 

As described by \cite{gneiting2007strictly}, when using the interval score $S_\alpha$, \enquote{the forecaster is rewarded for narrow prediction intervals, and he or she incurs a penalty, the size of which depends on $\alpha$, if the observation misses the interval}, which should provide it with an intuitive appeal.

However, we obtain predictions in a form of a vector of discharges in various time steps of a rain event. Therefore, we \enquote{extend} the idea of  $S_\alpha$ and evaluate the mean of interval scores ($M\!I\!S$) for every given   rain event. Analogically to this, we calculate as well the \enquote{average band width} ($A\!B\!W$) as the mean width of prediction intervals in the given period (similarly to \cite{giudice2013improving}).

However, we acknowledge that  uncertainty estimation based on  standard deviations of  predictions performance metrics (e.g. $dV$)  is reliable only as far as the predictions themselves are reliable. If the reliability is too low (below the defined confidence level $1- \alpha$), the $sd$ of a given metric does not reflect the metric's uncertainty reliably. In this case, the interval score $S_\alpha$ (expanded to  $M\!I\!S$ in our case) proves its worth, since it combines the uncertainty estimation based purely on predictions with the reliability obtained after comparing the predictions with observations.

In many similar cases, it is usual to confirm the statistical assumptions of the error model by residual analysis \citep{reichert2012linking}. However, Bayesian approach implemented in this method allows us to test only the observation error $E$, which is the only purely frequentist term. 

According to \cite{giudice2013improving}, this test can be performed on the predictive distribution of the observation error, predicted for the calibration data. It should be verified whether the observation errors are normally distributed with constant variance and without autocorrelation. However, since these errors are likely to constitute only a small portion of the residuals of the deterministic simulator, the informative value of this analysis might be limited.

